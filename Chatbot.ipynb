{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RSYyUYGxT8jI",
        "outputId": "c1923f96-1cd1-4cc0-92c8-d02bd87a4c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu, sentence-transformers\n",
            "Successfully installed faiss-cpu-1.9.0 sentence-transformers-3.2.0\n",
            "Collecting groq\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.11.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers faiss-cpu pandas transformers\n",
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQFuNcAQYUPT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "import re\n",
        "import json\n",
        "import google.generativeai as genai\n",
        "from groq import Groq\n",
        "import time\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate a Grock API key by following the below instructions:\n",
        "\n",
        "- Signup/login https://console.groq.com/login\n",
        "- Create a new api key\n",
        "- copy the generated key and paste it in below cell.\n"
      ],
      "metadata": {
        "id": "0UsxGSX8R7kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grok_api_key = \"\" # PASTE YOUR API KEY HERE"
      ],
      "metadata": {
        "id": "CIQNpYykVR9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ0uX2WcYayV"
      },
      "outputs": [],
      "source": [
        "# make sure you upload the dataset to colab before running the below,\n",
        "# ensure correct path is entered\n",
        "csv_file_path = '/content/chatbot-combined.csv'\n",
        "df = pd.read_csv(csv_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxkB_sB-YdQM",
        "outputId": "fe3a497c-b550-48d9-e05c-a3db889b61a9",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate embeddings for the questions\n",
        "questions = df['question'].tolist()\n",
        "question_embeddings = model.encode(questions, convert_to_tensor=False)\n",
        "\n",
        "# Convert embeddings to float32 (required by FAISS)\n",
        "question_embeddings = np.array(question_embeddings, dtype='float32')\n",
        "\n",
        "# Create a FAISS index for fast retrieval\n",
        "index = faiss.IndexFlatL2(question_embeddings.shape[1])  # L2 distance for similarity search\n",
        "index.add(question_embeddings)  # Add question embeddings to the index\n",
        "\n",
        "\n",
        "# Define retrieval function to get the closest answer\n",
        "def get_top_answer(query, model, faiss_index, df, top_k=3):\n",
        "    # Generate embedding for the input query\n",
        "    query_embedding = model.encode([query], convert_to_tensor=False)\n",
        "    query_embedding = np.array(query_embedding, dtype='float32')\n",
        "\n",
        "    # Search in the FAISS index\n",
        "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
        "\n",
        "    # Retrieve the best matching documents\n",
        "    retrieved_docs = []\n",
        "    for idx in indices[0]:\n",
        "        retrieved_docs.append(df.iloc[idx]['answer'])\n",
        "\n",
        "    return retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def GroqChat(question):\n",
        "    client = Groq(\n",
        "        api_key=grok_api_key,\n",
        "\n",
        "    )\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            }\n",
        "        ],\n",
        "            model = \"llama-3.1-70b-versatile\"\n",
        "    )\n",
        "\n",
        "    cleaned_json_string = chat_completion.choices[0].message.content\n",
        "\n",
        "    json_str = re.sub(r'}\\s*{', '}, {', cleaned_json_string)\n",
        "    return json_str"
      ],
      "metadata": {
        "id": "5p4MyQW8VINH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOuaNo2KYgmU"
      },
      "outputs": [],
      "source": [
        "def generate_answer_from_docs(query, retrieved_docs):\n",
        "    result = []\n",
        "    if not retrieved_docs:\n",
        "        return \"Don't have an answer for the query.\"\n",
        "\n",
        "    context = \"\\n\".join(retrieved_docs)\n",
        "    result.append(context)\n",
        "    # print(\"Context: \", context)\n",
        "\n",
        "    prompt = f\"Answer the following query, based only on the given context.Do not add anything from your previous learnings. Do not state in answer that a context is provided to you. If the context seems irrelavant just say 'I don't have an appropriate answer' query: {query} context: {context}\"\n",
        "    groq_answer = GroqChat(prompt)\n",
        "    result.append(groq_answer)\n",
        "    result.append('')\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask your question here:"
      ],
      "metadata": {
        "id": "zAh1-4JgrrVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  query = input(\"Enter your query here: \")\n",
        "  if query == \"exit\":\n",
        "    break\n",
        "  retrieved_docs = list(set(get_top_answer(query, model, index, df)))\n",
        "  generated_answer = generate_answer_from_docs(query, retrieved_docs)\n",
        "  print(\"Llama Answer: \", generated_answer[1])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elmv_yW6rpeu",
        "outputId": "684dd757-46bd-4292-94ce-6b072df17db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query here: What is Sitare univ?\n",
            "Llama Answer:  Sitare University is an institution that provides free high-quality Computer Science education to bright students from underprivileged backgrounds, covering food, accommodation, and studies expenses.\n",
            "\n",
            "Enter your query here: Who is FOunder?\n",
            "Llama Answer:  The founder of Sitare University is Dr. Amit Singhal, who was earlier Senior Vice President of Google Search.\n",
            "\n",
            "Enter your query here: Who is dean at SU?\n",
            "Llama Answer:  Dr. Anuja Agarwal is the founding Dean at Sitare University.\n",
            "\n",
            "Enter your query here: What is the fee structure?\n",
            "Llama Answer:  There is no application fee. Additionally, the university provides high-quality education and placements without any charges for the students, as it is free of cost for students from underprivileged backgrounds.\n",
            "\n",
            "Enter your query here: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1eooWuaYukZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}